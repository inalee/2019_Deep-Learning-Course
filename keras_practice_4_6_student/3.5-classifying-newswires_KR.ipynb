{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 기사 분류: 다중 분류 문제\n",
    "\n",
    "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다.\n",
    "\n",
    "----\n",
    "\n",
    "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
    "\n",
    "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로이터 데이터셋\n",
    "\n",
    "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
    "\n",
    "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
    "\n",
    "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  3,  4,  4,  4,  4,  3,  3, 16], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 데이터 벡터 변환\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# 테스트 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# 훈련 레이블 벡터 변환\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "# 테스트 레이블 벡터 변환\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성\n",
    "\n",
    "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
    "\n",
    "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 병목이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
    "\n",
    "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\82104\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\82104\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\82104\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
    "\n",
    "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
    "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
    "\n",
    "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\82104\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\82104\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 검증\n",
    "\n",
    "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 20번의 에포크로 모델을 훈련시킵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\82104\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\82104\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 2.7951 - acc: 0.4266 - val_loss: 1.8567 - val_acc: 0.6180\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - ETA: 0s - loss: 1.5031 - acc: 0.696 - 1s 90us/step - loss: 1.4950 - acc: 0.6988 - val_loss: 1.3445 - val_acc: 0.7070\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 1.0883 - acc: 0.7740 - val_loss: 1.1760 - val_acc: 0.7460\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.8530 - acc: 0.8231 - val_loss: 1.0723 - val_acc: 0.7600\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.6744 - acc: 0.8607 - val_loss: 0.9683 - val_acc: 0.7920\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.5400 - acc: 0.8899 - val_loss: 0.9167 - val_acc: 0.8070\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 93us/step - loss: 0.4331 - acc: 0.9108 - val_loss: 0.9231 - val_acc: 0.8110\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.3503 - acc: 0.9280 - val_loss: 0.9076 - val_acc: 0.8070\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.2958 - acc: 0.9377 - val_loss: 0.8939 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 93us/step - loss: 0.2468 - acc: 0.9445 - val_loss: 0.9177 - val_acc: 0.8200\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.2118 - acc: 0.9470 - val_loss: 0.9595 - val_acc: 0.8090\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.1849 - acc: 0.9520 - val_loss: 0.9459 - val_acc: 0.8160\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.1715 - acc: 0.9519 - val_loss: 0.9558 - val_acc: 0.8130\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.1529 - acc: 0.9525 - val_loss: 0.9990 - val_acc: 0.8090\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.1423 - acc: 0.9550 - val_loss: 0.9975 - val_acc: 0.8070\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.1328 - acc: 0.9563 - val_loss: 1.0090 - val_acc: 0.8070\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.1269 - acc: 0.9577 - val_loss: 1.0643 - val_acc: 0.7980\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.1187 - acc: 0.9583 - val_loss: 1.0589 - val_acc: 0.7930\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.1137 - acc: 0.9582 - val_loss: 1.0496 - val_acc: 0.8110\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.1149 - acc: 0.9580 - val_loss: 1.0674 - val_acc: 0.8090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실과 정확도 곡선을 그려 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZgU1bnH8e8Lgsgiu6Agi0qigoA4okZUXMIFNxIgQcTrgoZoxC0xN0RM9BrRxKgxKvGK29U4AYkGhRvFRIJB48aggApRUBFHEAGRfRt47x+nhmmG7pmepbpnpn+f5+mnazlV/XZNT71Vp6rOMXdHRERyV71sByAiItmlRCAikuOUCEREcpwSgYhIjlMiEBHJcUoEIiI5TolA9mJm9c1so5l1qs6y2WRmh5lZtd8rbWZnmNnShPEPzOykdMpW4rMeNrMbKru8SCr7ZDsAqToz25gw2hjYBuyMxn/o7vkVWZ+77wSaVnfZXODu36yO9ZjZZcAF7t4/Yd2XVce6RUpTIqgD3H33jjg64rzM3V9KVd7M9nH3okzEJlIe/R6zT1VDOcDMbjWzp8xskpltAC4wsxPM7A0z+9rMVpjZvWbWICq/j5m5mXWJxp+M5r9gZhvM7HUz61rRstH8QWb2oZmtM7P7zOxfZnZxirjTifGHZrbEzNaa2b0Jy9Y3s9+Z2Roz+wgYWMb2udHMJpeaNsHM7o6GLzOzRdH3+Sg6Wk+1rkIz6x8NNzazP0axvQ8ck+RzP47W+76ZnRtNPwq4HzgpqnZbnbBtb05Y/vLou68xs2fN7MB0tk1FtnNxPGb2kpl9ZWZfmNl/JXzOL6Jtst7MCszsoGTVcGb2avHfOdqes6PP+Qq40cy6mdms6LusjrZb84TlO0ffcVU0//dm1iiK+YiEcgea2WYza53q+0oS7q5XHXoBS4EzSk27FdgOnENI/vsBxwLHEc4KDwE+BMZE5fcBHOgSjT8JrAbygAbAU8CTlSh7ALABGBzN+zGwA7g4xXdJJ8bngOZAF+Cr4u8OjAHeBzoCrYHZ4eee9HMOATYCTRLW/SWQF42fE5Ux4DRgC9AzmncGsDRhXYVA/2j4TuBloCXQGVhYquz3gQOjv8n5UQztonmXAS+XivNJ4OZoeEAUY2+gEfAH4B/pbJsKbufmwErgGmBfYH+gbzTv58B8oFv0HXoDrYDDSm9r4NXiv3P03YqAK4D6hN/jN4DTgYbR7+RfwJ0J3+e9aHs2icqfGM2bCIxP+JyfAFOz/X9Y215ZD0Cvav6Dpk4E/yhnueuBP0fDyXbu/5NQ9lzgvUqUHQW8kjDPgBWkSARpxnh8wvy/ANdHw7MJVWTF884svXMqte43gPOj4UHAh2WU/T/gymi4rESwLPFvAfwosWyS9b4HnBUNl5cIHgduS5i3P+G6UMfytk0Ft/N/AgUpyn1UHG+p6ekkgo/LiWEYMCcaPgn4AqifpNyJwCeARePzgCHV/X9V11+qGsodnyWOmNnhZvbX6FR/PXAL0KaM5b9IGN5M2ReIU5U9KDEOD/+5halWkmaMaX0W8GkZ8QL8CRgRDZ8P7L7AbmZnm9mbUdXI14Sj8bK2VbEDy4rBzC42s/lR9cbXwOFprhfC99u9PndfD6wFOiSUSetvVs52PhhYkiKGgwnJoDJK/x7bm9kUM/s8iuF/S8Ww1MONCXtw938Rzi76mVkPoBPw10rGlLOUCHJH6VsnHyQcgR7m7vsDvyQcocdpBeGIFQAzM/bccZVWlRhXEHYgxcq7vfUp4Awz60iouvpTFON+wNPA7YRqmxbA39KM44tUMZjZIcADhOqR1tF6/52w3vJudV1OqG4qXl8zQhXU52nEVVpZ2/kz4NAUy6WatymKqXHCtPalypT+fr8h3O12VBTDxaVi6Gxm9VPE8QRwAeHsZYq7b0tRTlJQIshdzYB1wKboYtsPM/CZ/wf0MbNzzGwfQr1z25hinAJca2YdoguHPyursLuvJFRfPAZ84O6Lo1n7EuqtVwE7zexsQl12ujHcYGYtLDxnMSZhXlPCznAVISdeRjgjKLYS6Jh40baUScClZtbTzPYlJKpX3D3lGVYZytrO04BOZjbGzBqa2f5m1jea9zBwq5kdakFvM2tFSIBfEG5KqG9mo0lIWmXEsAlYZ2YHE6qnir0OrAFus3ABfj8zOzFh/h8JVUnnE5KCVJASQe76CXAR4eLtg4Qj4lhFO9vhwN2Ef+xDgXcIR4LVHeMDwEzgXWAO4ai+PH8i1Pn/KSHmr4HrgKmEC67DCAktHTcRzkyWAi+QsJNy9wXAvcBbUZnDgTcTlv07sBhYaWaJVTzFy88gVOFMjZbvBIxMM67SUm5nd18HfBsYSrg4/SFwSjT7t8CzhO28nnDhtlFU5fcD4AbCjQOHlfpuydwE9CUkpGnAMwkxFAFnA0cQzg6WEf4OxfOXEv7O2939tQp+d6HkAotIxkWn+suBYe7+SrbjkdrLzJ4gXIC+Odux1EZ6oEwyyswGEk71txJuPywiHBWLVEp0vWUwcFS2Y6mtVDUkmdYP+JhQZTAQ+I4u7kllmdnthGcZbnP3ZdmOp7ZS1ZCISI7TGYGISI6rddcI2rRp4126dMl2GCIitcrcuXNXu3vS27VrXSLo0qULBQUF2Q5DRKRWMbOUT9erakhEJMcpEYiI5DglAhGRHKdEICKS45QIRERynBKBiNR5+fnQpQvUqxfe8/PLW6JuLV+ubPeMU9HXMccc4yJSuzz5pHvnzu5m4f3JJzO3/JNPujdu7A4lr8aN019HbV++GCl6mnOvhV1VKhGIZF5t3hF37rznssWvzp1zY/liSgQitVxtPqLO9o7QLPnyZrmxfDElApEsqo6deG0+os72jjDbiSjbyxdTIhCpgmweTbtnf0dS23fE2U6k2V6+mBKBSCVl+2javfYfUdeEHWE2q9ZqwvLuSgQilZbto+nqiCHbO/LidWR7R5jrlAgkp1VlJ5Lto+ni+Gv7EbVknxKB5KxsV+1UV/2ujqilqspKBLWuq8q8vDxXfwSSri5d4NMkrbB37gxLl5a/fH4+jB4NmzeXTGvcGCZOhJEj04shPx/GjYNly6BTJxg/Pv1lRaqLmc1197yk85QIpC6rVy8ch5dmBrt2pbcO7cilLigrEaitIanxqtLOSqdOFZuezMiR4exh167wriQgdY0SgdRoxVUzn34ajuw//TSMp5sMxo8PVTmJGjcO00UkUCKQGm3cuD3r5yGMjxuX3vIjR4b6/M6dQ3VQ584Vq98XyQW6RiA1WnXU8YuIrhFILVYddfwiUjYlAqnRVMcvEj8lAoldVe76UR2/SPz2yXYAUreVfiCr+K4fSH9nPnKkdvwicdIZgcSqqnf9iEj8lAgkVsuWVWy6iGRerInAzAaa2QdmtsTMxiaZ39nMZprZAjN72cw6xhmPZJ7u+hGp+WJLBGZWH5gADAKOBEaY2ZGlit0JPOHuPYFbgNvjikeyQ3f9iNR8cZ4R9AWWuPvH7r4dmAwMLlXmSGBmNDwryXyp5XTXj0jNF2ci6AB8ljBeGE1LNB8YGg1/F2hmZq1Lr8jMRptZgZkVrFq1KpZgJT5qtE2kZoszEViSaaUbC7geOMXM3gFOAT4HivZayH2iu+e5e17btm2rP1IpU1WeAxCRmi/O5wgKgYMTxjsCyxMLuPtyYAiAmTUFhrr7uhhjkgqqjucARKRmi/OMYA7Qzcy6mllD4DxgWmIBM2tjZsUx/Bx4NMZ4pBL0HIBI3RdbInD3ImAM8CKwCJji7u+b2S1mdm5UrD/wgZl9CLQDdC9JDaPnAETqvlibmHD354HnS037ZcLw08DTccYgVdOpU/I+f/UcgEjdoSeLpUx6DkCk7lMikDLpOQCRuk+tj0q51PqnSN2mMwIRkRynRCAikuOUCEREcpwSQQ5QExEiUhZdLK7j1ESEiJRHZwR1nJqIEJHyKBHUcWoiQkTKo0RQx6mrSBEpjxJBHacmIkSkPEoEdZyaiBCR8uiuoRygJiJEpCw6IxARyXFKBCIiOU6JQEQkxykRiIjkOCUCEZEcp0QgIpLjlAhqAbUeKiJx0nMENZxaDxWRuOmMoIZT66E1gzts2JDtKETioTOCGk6th2bPZ5/BrFnwj3+E92XL4NBD4dRTS14HHpjtKEWqTomghuvUKVQHJZsu1euLL8IOv3jn/9FHYXrr1tC/P1x6KcydC3/+Mzz8cJh3+OFw2mkhKfTvD23aVF88O3fC0qWwaBEsXAiffAJNmkCrVnu/WrYM7/vvH9qUEqkIJYIabvz4Pa8RgFoPrS6rV8PLL5fs/BctCtObN4dTToExY8IO/qijwoX6Yjt3wrx5JWcKTzwBf/hDmNezZ8nZwimnQIsW5cexYwcsWRJ29sU7/YUL4YMPYOvWknKtWsGWLeGVSv36JUkhMUEUv9q1g/btS17t2u3dOq3kHnP3bMdQIXl5eV5QUJDtMDIqPz9cE1i2LJwJjB9fMy8Ub9sGX34ZjqyLXytXlgyvWxeOmJPtjNq3h7ZtYZ8YD02+/hpmzy454l+wIExv0gROOqnkyP7oo8MONV07dkBBQUlCefXVsAOvVy+s69RTw7qPPRY+/7xkR1+801+8GIqKStbXuTMceSQccUR4Lx4uTipbt8LatfDVV3u/ypr+9dfJ42/WLPnfo/S0Aw6Ahg0rt+1z2fbtMHVq+D/esQOaNt371aRJ8uml5zdoUPk4zGyuu+clnadEIOnYuBFeew2WL99z5564s1+7NvmyLVuGnUnz5uEofOXK5BdezUIySNwRJQ63ahV2ghs37v3atCn59MTXtm3hcxo1ghNPLDlyP/bYqv2DlbZtG7z5ZskZwxtvhJ1Bonr14LDDSnb2xe/f/Gb4h49DURGsWpU6USeOp0oajRqVv7NK9WrcuGIJtrT69cN2ateu8uvIpM8/hwcfhIceCtu0c+eQTBN/kxs27HkQUJ4JE+BHP6pcPFlLBGY2EPg9UB942N1/XWp+J+BxoEVUZqy7P1/WOpUIMmfbNpgxAyZNgunT96yeato09ZF94uuAA2Dfffde96ZNJTudVDuj4lfxDjyV0jugVDukli3hhBPg+OOTxxSXzZtDEp03L5zRHXEEfOMbmY2horZu3fvvU5zA00m6pe90q06dOoXk3bdveD/mmHBtpCZwD9WNEybAs8/Crl1w5plw5ZXwH/+xZxVjse3by9+mxfMHDQrftzKykgjMrD7wIfBtoBCYA4xw94UJZSYC77j7A2Z2JPC8u3cpa71KBPHauTP8kCdNgmeeCUeGrVvDsGEwZEi4a6Zdu/iOWktzh/Xrw47oq6/CUWXizr5x4+T/XJJdu3aFZFB6h1aV3c22baE6b84ceOst+PjjMN0sXLRPTA69emU20W7YUHKtaOHCcPZ66aVw+eVwyCGZi6MsZSWCOC8W9wWWuPvHURCTgcHAwoQyDhTn8ubA8hjjkRTcQ1XGpEkwZUrY6TZtCt/5DowYAd/+dvVWnVSEWahSat48O58vlVOvXsmZWHU644yS4dWrw7WZ4sTw4othZwzh99qr157J4fDDq1Y1lczCheHo/4knQqLLy4PHHoPhw2G//ar3s+IU5xnBMGCgu18Wjf8ncJy7j0kocyDwN6Al0AQ4w93nJlnXaGA0QKdOnY75NNn9lFJh770Xdv6TJ4ejq4YN4ayzws7/rLN0N4nULu7h2Y/ixDBnTkgUxdejmjQJR+cHHxyql4pfxeMdOqR3wLNjBzz3XEgAL78czjyGDw/VP337xvoVqyRbZwTJ7mYunXVGAP/r7neZ2QnAH82sh7vv2mMh94nARAhVQ7FEmyM++STs/CdNComgXr1wlPWLX8B3v6sjb6m9zEp27kOHhmm7doXbcOfMCc+ALF0a7r57801Ys2bv5Q86aO9EUZwsmjUL/zcPPhhumujcGX7961AFVJ3Pj2RDnImgEDg4Ybwje1f9XAoMBHD3182sEdAG+DLGuHLS7Nnws5+FO1gAvvUtuO8++N73as9dGCIVVa9euDh/xBFw4YV7ztu0KZxBLFtW8l48/M474ag/2Y0KAweGZDBoUPVXNWVLnIlgDtDNzLoCnwPnAeeXKrMMOB34XzM7AmgErIoxppyzcyfcfjvcdFPJEcx554VhkVzWpEm4bnD44cnnu4fbbYuTxMqV4ez5sMMyG2cmxJYI3L3IzMYALxJuDX3U3d83s1uAAnefBvwEeMjMriNUG13ste3Bhhrsiy/gggtg5kw4/3z4n/8Jp7ciUj6zcPvzAQdU/pbN2iLWJiaiZwKeLzXtlwnDC4ET44whV730Unj6eMMGeOQRuOQStUEjIsnpDuw6pqgIbrwRBgwIF7DmzIFRo5QERCQ1JYIMyFQPY4WFoU2b8ePDGcBbb0H37vF8lojUHWp9NGaZ6mHsr3+Fiy4KTQP88Y/h2oCISDp0RhCzuHsY274dfvpTOPts6NgR3n5bSUBEKkZnBDGLs4expUvDraBvvhlaJLzrrtA6pIhIReiMIGapehKrag9jf/lLaOt+0aLQY9aECUoCIlI5SgQxGz9+7zZ7qtLD2NatcNVV4RH6bt3CE5DDhlU9ThHJXUoEMRs5EiZODE/ymoX3iRMrd6F4yZLQNMT998OPfxx6wqopTdyKSO2lawQZMHJk5e8Q2rULXn899A3w8MOhdcRp0+Ccc6o3RhHJXUoENVBREbzyCjz9dOjrdMWKkiaif//70BKiiEh1USKoIbZvD33cPvNM6OJu9erQscWZZ4brAWedVXO64xORukWJIIu2boW//S3s/KdNC91CNmsWngkYNiw0d6vOYUQkbkoEGbZpEzz/fNj5//WvoXu7li1Dt5BDh4ZmbnUbqIhkkhJBhixcGHoBe+EF2LIF2rYNTUMPHQqnnpq9PoFFRMpNBFGfAvnuvjYD8dRJ//pXqO6pXz90azdsGPTrV3d6NxKR2i2dM4L2wBwzext4FHhRncekb9q00LF1p07w4ouh9VERkZqk3AfK3P1GoBvwCHAxsNjMbjOzQ2OOrdZ75JHQIXzPnuHhLyUBEamJ0nqyODoD+CJ6FQEtgafN7I4YY6u13OG22+Cyy+Db3w5dRbZtm+2oRESSS+cawdXARcBq4GHgp+6+w8zqAYuB/4o3xNpl1y649lq4777QHPSjj+pCsIjUbOlcI2gDDHH3TxMnuvsuMzs7nrBqp23b4MILYcoU+MlP4I47Qq9kIiI1WTq7qeeBr4pHzKyZmR0H4O6L4gqstlm/PjwFPGUK/Pa3cOedSgIiUjuks6t6ANiYML4pmiaRL76A/v1h9mx44gm4/vpsRyQikr50qoYs8XbRqEpID6JFPvoIBgwIyWD69NAshIhIbZLOGcHHZna1mTWIXtcAH8cdWG3w9tuhf4B160KDcUoCIlIbpZMILge+BXwOFALHAaPjDKo2mDkTTjkltBD6r3/BccdlOyIRkcopt4rH3b8EzstALLXGU0/Bf/4nHH44zJgBBx2U7YhERCovnecIGgGXAt2B3e1iuvuoGOOqse67D665Bk46CZ57Dlq0yHZEIiJVk07V0B8J7Q39B/BPoCOwIc6gaiJ3uOEGuPrq0GT0iy8qCYhI3ZBOIjjM3X8BbHL3x4GzgKPSWbmZDTSzD8xsiZmNTTL/d2Y2L3p9aGZfVyz8zLnvPrj9dhg9Gv78Z/UZICJ1RzqJYEf0/rWZ9QCaA13KW8jM6gMTgEHAkcAIMzsysYy7X+fuvd29N3Af8JcKxJ4xjz0GP/5xGJ4xAyZPzm48IiLVKZ1EMNHMWgI3AtOAhcBv0liuL7DE3T929+3AZGBwGeVHAJPSWG9G5efDD38IO3eG8WXLwllBfn524xIRqS5lJoKoYbn17r7W3We7+yHufoC7P5jGujsAnyWMF0bTkn1OZ6Ar8I8U80ebWYGZFaxatSqNj64+N9wAO3bsOW3zZhg3LqNhiIjEpsxE4O67gDGVXLclW2WKsucBT7v7zhRxTHT3PHfPa5vh9pyXLavYdBGR2iadqqG/m9n1ZnawmbUqfqWxXCFwcMJ4R2B5irLnUQOrhXbuhH1S3GDbqVNmYxERiUs6bQYVPy9wZcI0Bw4pZ7k5QDcz60p4Kvk84PzShczsm4SObl5PI5aMmjIFioqgYUPYvr1keuPGMH589uISEalO6XRV2TXJq7wkgLsXEaqVXgQWAVPc/X0zu8XMzk0oOgKYXNP6Qd61K+zsu3eHhx+Gzp3BLLxPnAgjR2Y7QhGR6mHl7X/N7MJk0939iVgiKkdeXp4XFBTE/jlTp8KQIfCnP8GIEbF/nIhIrMxsrrvnJZuXTtXQsQnDjYDTgbeBrCSCTHCHW2+Fbt3g+9/PdjQiIvFKp9G5qxLHzaw5odmJOmvGjNDE9KOPQv362Y5GRCRelelMcTPQrboDqSnc4Ve/CncFXXBBtqMREYlfOq2PTqfk/v96hOYipsQZVDa9/DK8/jr84Q/QoEG2oxERiV861wjuTBguAj5198KY4sm6W2+FAw+ESy7JdiQiIpmRTiJYBqxw960AZrafmXVx96WxRpYFr70Wupy86y61LioiuSOdawR/BnYljO+MptU548dD69ahkTkRkVyRTiLYJ2o9FIBouGF8IWXHO+/A88+H5qabNMl2NCIimZNOIliV+CSwmQ0GVscXUnaMHw/Nm8OVV5ZfVkSkLknnGsHlQL6Z3R+NFwJJnzaurd5/H555Bn7xi5AMRERySToPlH0EHG9mTQlNUtS5/opvvz1UB11zTbYjERHJvHKrhszsNjNr4e4b3X2DmbU0s1szEVwmLFkCkybBj34ULhSLiOSadK4RDHL33Z3Ku/ta4Mz4QsqsX/86NDNd3CexiEiuSScR1DezfYtHzGw/YN8yytcay5bB44/DD34A7dtnOxoRkexI52Lxk8BMM3ssGr8EeDy+kDLnjjtCHwM//Wm2IxERyZ50LhbfYWYLgDMI/RDPADrHHVjcVqwIHc5cfDEcfHC5xUVE6qx0Wx/9gvB08VBCfwSLYosoQ+66K3RDOXZstiMREcmulGcEZvYNQj/DI4A1wFOE20dPzVBssVm9Gh54AM4/Hw4pt9NNEZG6rayqoX8DrwDnuPsSADO7LiNRxeyee2DLFvj5z7MdiYhI9pVVNTSUUCU0y8weMrPTCdcIarWvv4b77oOhQ+GII7IdjYhI9qVMBO4+1d2HA4cDLwPXAe3M7AEzG5Ch+KrdhAmwfj2MG5ftSEREaoZyLxa7+yZ3z3f3s4GOwDygVl5i3bgRfvc7OPts6N0729GIiNQMFeqz2N2/cvcH3f20uAKK04MPwpo1OhsQEUlUmc7ra6UtW+DOO+GMM+D447MdjYhIzZHOk8V1wqOPwhdfwOTJ2Y5ERKRmyZkzgm99K9wuevLJ2Y5ERKRmyZkzgqOPDi8REdlTzpwRiIhIcrEmAjMbaGYfmNkSM0t6y6mZfd/MFprZ+2b2pzjjERGRvcVWNWRm9YEJwLcJ/RzPMbNp7r4woUw34OfAie6+1swOiCseERFJLs4zgr7AEnf/2N23A5OBwaXK/ACYEPV6hrt/GWM8IiKSRJyJoAPwWcJ4YTQt0TeAb5jZv8zsDTMbmGxFZjbazArMrGDVqlUxhSsikpviTATJGqjzUuP7AN2A/oTmrh82sxZ7LeQ+0d3z3D2vbdu21R6oiEguizMRFAKJfX91BJYnKfOcu+9w90+ADwiJQUREMiTORDAH6GZmXc2sIaGTm2mlyjwLnApgZm0IVUUfxxiTiIiUElsicPciYAzwIqFryynu/r6Z3WJm50bFXgTWmNlCYBbwU3dfE1dMIiKyN3MvXW1fs+Xl5XlBQUG2wxARqVXMbK675yWbpyeLRURynBKBiEiOUyIQEclxSgQiIjlOiUBEJMcpEYiI5DglAhGRHKdEICKS45QIRERynBKBiEiOUyIQEclxSgQiIjlOiUBEJMcpEYiI5DglAhGRHKdEICKS45QIRERynBKBiEiOUyIQEclxSgQiIjlOiUBEJMcpEYiI5DglAhGRHKdEICKS45QIRERynBKBiEiOUyIQEclxSgQiIjku1kRgZgPN7AMzW2JmY5PMv9jMVpnZvOh1WZzxiIjI3vaJa8VmVh+YAHwbKATmmNk0d19YquhT7j4mrjhERKRscZ4R9AWWuPvH7r4dmAwMjvHzRESkEmI7IwA6AJ8ljBcCxyUpN9TMTgY+BK5z98+SlBGRLNuxYweFhYVs3bo126FIGRo1akTHjh1p0KBB2svEmQgsyTQvNT4dmOTu28zscuBx4LS9VmQ2GhgN0KlTp+qOU0TSUFhYSLNmzejSpQtmyf69JdvcnTVr1lBYWEjXrl3TXi7OqqFC4OCE8Y7A8sQC7r7G3bdFow8BxyRbkbtPdPc8d89r27ZtLMGKSNm2bt1K69atlQRqMDOjdevWFT5rizMRzAG6mVlXM2sInAdMSyxgZgcmjJ4LLIoxHhGpIiWBmq8yf6PYqobcvcjMxgAvAvWBR939fTO7BShw92nA1WZ2LlAEfAVcHFc8IiKSXKzPEbj78+7+DXc/1N3HR9N+GSUB3P3n7t7d3Xu5+6nu/u844xGRzMnPhy5doF698J6fX7X1rVmzht69e9O7d2/at29Phw4ddo9v3749rXVccsklfPDBB2WWmTBhAvlVDbaWifNisYjkqPx8GD0aNm8O459+GsYBRo6s3Dpbt27NvHnzALj55ptp2rQp119//R5l3B13p1695Me4jz32WLmfc+WVV1YuwFpMTUyISLUbN64kCRTbvDlMr25LliyhR48eXH755fTp04cVK1YwevRo8vLy6N69O7fccsvusv369WPevHkUFRXRokULxo4dS69evTjhhBP48ssvAbjxxhu55557dpcfO3Ysffv25Zvf/CavvfYaAJs2bWLo0KH06tWLESNGkJeXtztJJbrppps49thjd8fnHm6c/PDDDznttNPo1asXffr0YenSpQDcdtttHHXUUfTq1YtxcWysFJQIRKTaLVtWselVtXDhQi699FLeeecdOnTowK9//WsKCgqYP38+f//731m4sHSDBrBu3TpOOeUU5s+fzwknnMCjj8RYX4cAAA6qSURBVD6adN3uzltvvcVvf/vb3Unlvvvuo3379syfP5+xY8fyzjvvJF32mmuuYc6cObz77rusW7eOGTNmADBixAiuu+465s+fz2uvvcYBBxzA9OnTeeGFF3jrrbeYP38+P/nJT6pp65RPiUBEql2qx33iegzo0EMP5dhjj909PmnSJPr06UOfPn1YtGhR0kSw3377MWjQIACOOeaY3UflpQ0ZMmSvMq+++irnnXceAL169aJ79+5Jl505cyZ9+/alV69e/POf/+T9999n7dq1rF69mnPOOQcID4A1btyYl156iVGjRrHffvsB0KpVq4pviEpSIhCRajd+PDRuvOe0xo3D9Dg0adJk9/DixYv5/e9/zz/+8Q8WLFjAwIEDk95X37Bhw93D9evXp6ioKOm69913373KFFfxlGXz5s2MGTOGqVOnsmDBAkaNGrU7jmS3eLp71m7PVSIQkWo3ciRMnAidO4NZeJ84sfIXiiti/fr1NGvWjP33358VK1bw4osvVvtn9OvXjylTpgDw7rvvJj3j2LJlC/Xq1aNNmzZs2LCBZ555BoCWLVvSpk0bpk+fDoQH9TZv3syAAQN45JFH2LJlCwBfffVVtcediu4aEpFYjByZmR1/aX369OHII4+kR48eHHLIIZx44onV/hlXXXUVF154IT179qRPnz706NGD5s2b71GmdevWXHTRRfTo0YPOnTtz3HElTa3l5+fzwx/+kHHjxtGwYUOeeeYZzj77bObPn09eXh4NGjTgnHPO4Ve/+lW1x56MpXOKU5Pk5eV5QUFBtsMQyTmLFi3iiCOOyHYYNUJRURFFRUU0atSIxYsXM2DAABYvXsw++9SMY+tkfyszm+vuecnK14yoRURqkY0bN3L66adTVFSEu/Pggw/WmCRQGbU3chGRLGnRogVz587NdhjVRheLRURynBKBiEiOUyIQEclxSgQiIjlOiUBEaoX+/fvv9XDYPffcw49+9KMyl2vatCkAy5cvZ9iwYSnXXd5t6ffccw+bE1rSO/PMM/n666/TCb3GUyIQkVphxIgRTJ48eY9pkydPZsSIEWktf9BBB/H0009X+vNLJ4Lnn3+eFi1aVHp9NYluHxWRCrv2WkjS6nKV9O4NUevPSQ0bNowbb7yRbdu2se+++7J06VKWL19Ov3792LhxI4MHD2bt2rXs2LGDW2+9lcGDB++x/NKlSzn77LN577332LJlC5dccgkLFy7kiCOO2N2sA8AVV1zBnDlz2LJlC8OGDeO///u/uffee1m+fDmnnnoqbdq0YdasWXTp0oWCggLatGnD3Xffvbv10ssuu4xrr72WpUuXMmjQIPr168drr71Ghw4deO6553Y3Klds+vTp3HrrrWzfvp3WrVuTn59Pu3bt2LhxI1dddRUFBQWYGTfddBNDhw5lxowZ3HDDDezcuZM2bdowc+bMKm97JQIRqRVat25N3759mTFjBoMHD2by5MkMHz4cM6NRo0ZMnTqV/fffn9WrV3P88cdz7rnnpmzE7YEHHqBx48YsWLCABQsW0KdPn93zxo8fT6tWrdi5cyenn346CxYs4Oqrr+buu+9m1qxZtGnTZo91zZ07l8cee4w333wTd+e4447jlFNOoWXLlixevJhJkybx0EMP8f3vf59nnnmGCy64YI/l+/XrxxtvvIGZ8fDDD3PHHXdw11138atf/YrmzZvz7rvvArB27VpWrVrFD37wA2bPnk3Xrl2rrT0iJQIRqbCyjtzjVFw9VJwIio/C3Z0bbriB2bNnU69ePT7//HNWrlxJ+/btk65n9uzZXH311QD07NmTnj177p43ZcoUJk6cSFFREStWrGDhwoV7zC/t1Vdf5bvf/e7uFlCHDBnCK6+8wrnnnkvXrl3p3bs3kLqp68LCQoYPH86KFSvYvn07Xbt2BeCll17aoyqsZcuWTJ8+nZNPPnl3mepqqjonrhFUd9+pIpId3/nOd5g5cyZvv/02W7Zs2X0kn5+fz6pVq5g7dy7z5s2jXbt2SZueTpTsbOGTTz7hzjvvZObMmSxYsICzzjqr3PWU1V5bcRPWkLqp66uuuooxY8bw7rvv8uCDD+7+vGTNUsfVVHWdTwTFfad++im4l/SdqmQgUvs0bdqU/v37M2rUqD0uEq9bt44DDjiABg0aMGvWLD799NMy13PyySfv7qD+vffeY8GCBUBowrpJkyY0b96clStX8sILL+xeplmzZmzYsCHpup599lk2b97Mpk2bmDp1KieddFLa32ndunV06NABgMcff3z39AEDBnD//ffvHl+7di0nnHAC//znP/nkk0+A6muqus4ngkz2nSoi8RsxYgTz58/f3UMYwMiRIykoKCAvL4/8/HwOP/zwMtdxxRVXsHHjRnr27Mkdd9xB3759gdDb2NFHH0337t0ZNWrUHk1Yjx49mkGDBnHqqafusa4+ffpw8cUX07dvX4477jguu+wyjj766LS/z80338z3vvc9TjrppD2uP9x4442sXbuWHj160KtXL2bNmkXbtm2ZOHEiQ4YMoVevXgwfPjztzylLnW+Gul69cCZQmhns2lWNgYnUcWqGuvaoaDPUdf6MINN9p4qI1DZ1PhFkuu9UEZHaps4ngmz2nSpS19S2quRcVJm/UU48R5CtvlNF6pJGjRqxZs0aWrduHcstjFJ17s6aNWto1KhRhZbLiUQgIlXXsWNHCgsLWbVqVbZDkTI0atSIjh07VmgZJQIRSUuDBg12P9EqdUudv0YgIiJlUyIQEclxSgQiIjmu1j1ZbGargLIbEsmeNsDqbAdRBsVXNTU9Pqj5MSq+qqlKfJ3dvW2yGbUuEdRkZlaQ6hHumkDxVU1Njw9qfoyKr2riik9VQyIiOU6JQEQkxykRVK+J2Q6gHIqvamp6fFDzY1R8VRNLfLpGICKS43RGICKS45QIRERynBJBBZnZwWY2y8wWmdn7ZnZNkjL9zWydmc2LXr/McIxLzezd6LP36s7NgnvNbImZLTCzPhmM7ZsJ22Wema03s2tLlcn49jOzR83sSzN7L2FaKzP7u5ktjt5bplj2oqjMYjO7KEOx/dbM/h39/aaaWYsUy5b5W4g5xpvN7POEv+OZKZYdaGYfRL/HsRmM76mE2Jaa2bwUy8a6DVPtUzL6+3N3vSrwAg4E+kTDzYAPgSNLlekP/F8WY1wKtClj/pnAC4ABxwNvZinO+sAXhAddsrr9gJOBPsB7CdPuAMZGw2OB3yRZrhXwcfTeMhpumYHYBgD7RMO/SRZbOr+FmGO8Gbg+jd/AR8AhQENgfun/p7jiKzX/LuCX2diGqfYpmfz96Yyggtx9hbu/HQ1vABYBHbIbVYUNBp7w4A2ghZkdmIU4Tgc+cvesPynu7rOBr0pNHgw8Hg0/DnwnyaL/Afzd3b9y97XA34GBccfm7n9z96Jo9A2gYu0OV7MU2y8dfYEl7v6xu28HJhO2e7UqKz4LnSt8H5hU3Z+bjjL2KRn7/SkRVIGZdQGOBt5MMvsEM5tvZi+YWfeMBgYO/M3M5prZ6CTzOwCfJYwXkp1kdh6p//myuf2KtXP3FRD+WYEDkpSpCdtyFOEML5nyfgtxGxNVXz2aomqjJmy/k4CV7r44xfyMbcNS+5SM/f6UCCrJzJoCzwDXuvv6UrPfJlR39ALuA57NcHgnunsfYBBwpZmdXGp+su6lMnofsZk1BM4F/pxkdra3X0VkdVua2TigCMhPUaS830KcHgAOBXoDKwjVL6Vl/bcIjKDss4GMbMNy9ikpF0syrcLbT4mgEsysAeEPlu/ufyk9393Xu/vGaPh5oIGZtclUfO6+PHr/EphKOP1OVAgcnDDeEViemeh2GwS87e4rS8/I9vZLsLK4yix6/zJJmaxty+jC4NnASI8qjEtL47cQG3df6e473X0X8FCKz87qb9HM9gGGAE+lKpOJbZhin5Kx358SQQVF9YmPAIvc/e4UZdpH5TCzvoTtvCZD8TUxs2bFw4SLiu+VKjYNuDC6e+h4YF3xKWgGpTwKy+b2K2UaUHwXxkXAc0nKvAgMMLOWUdXHgGharMxsIPAz4Fx335yiTDq/hThjTLzu9N0Unz0H6GZmXaOzxPMI2z1TzgD+7e6FyWZmYhuWsU/J3O8vrivhdfUF9COcei0A5kWvM4HLgcujMmOA9wl3QLwBfCuD8R0Sfe78KIZx0fTE+AyYQLhb410gL8PbsDFhx948YVpWtx8hKa0AdhCOsi4FWgMzgcXRe6uobB7wcMKyo4Al0euSDMW2hFA3XPwb/J+o7EHA82X9FjK4/f4Y/b4WEHZqB5aOMRo/k3CnzEdxxZgsvmj6/xb/7hLKZnQblrFPydjvT01MiIjkOFUNiYjkOCUCEZEcp0QgIpLjlAhERHKcEoGISI5TIhCJmNlO27Nl1GprCdPMuiS2fClSk+yT7QBEapAt7t4720GIZJrOCETKEbVH/xszeyt6HRZN72xmM6NG1WaaWadoejsLfQTMj17filZV38weitqc/5uZ7ReVv9rMFkbrmZylryk5TIlApMR+paqGhifMW+/ufYH7gXuiafcTmvPuSWj07d5o+r3APz00mteH8EQqQDdggrt3B74GhkbTxwJHR+u5PK4vJ5KKniwWiZjZRndvmmT6UuA0d/84ahzsC3dvbWarCc0m7Iimr3D3Nma2Cujo7tsS1tGF0G58t2j8Z0ADd7/VzGYAGwmtrD7rUYN7IpmiMwKR9HiK4VRlktmWMLyTkmt0ZxHafjoGmBu1iCmSMUoEIukZnvD+ejT8GqG1TICRwKvR8EzgCgAzq29m+6daqZnVAw5291nAfwEtgL3OSkTipCMPkRL72Z4dmM9w9+JbSPc1szcJB08jomlXA4+a2U+BVcAl0fRrgIlmdinhyP8KQsuXydQHnjSz5oRWYX/n7l9X2zcSSYOuEYiUI7pGkOfuq7Mdi0gcVDUkIpLjdEYgIpLjdEYgIpLjlAhERHKcEoGISI5TIhARyXFKBCIiOe7/AYsESSLALSwcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그래프를 초기화합니다\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 2.5671 - acc: 0.5164 - val_loss: 1.6916 - val_acc: 0.6420\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 1.3863 - acc: 0.7121 - val_loss: 1.2837 - val_acc: 0.7360\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 1.0175 - acc: 0.7863 - val_loss: 1.1590 - val_acc: 0.7380\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.7965 - acc: 0.8319 - val_loss: 1.0239 - val_acc: 0.7870\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.6320 - acc: 0.8707 - val_loss: 0.9541 - val_acc: 0.8010\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.4978 - acc: 0.8983 - val_loss: 0.9170 - val_acc: 0.8160\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.3991 - acc: 0.9201 - val_loss: 0.8943 - val_acc: 0.8150\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.3254 - acc: 0.9323 - val_loss: 0.9274 - val_acc: 0.8020\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.2695 - acc: 0.9429 - val_loss: 0.9064 - val_acc: 0.8140\n",
      "2246/2246 [==============================] - 0s 86us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9837138939413341, 0.7862867319944812]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19011576135351738"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 데이터에 대해 예측하기\n",
    "\n",
    "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.0832891e-06, 1.0260281e-04, 7.9159772e-06, 7.1013176e-01,\n",
       "       2.8097361e-01, 3.5872759e-05, 5.3227786e-06, 1.4260900e-05,\n",
       "       1.6755720e-03, 1.8319253e-05, 2.5861882e-06, 8.3215232e-04,\n",
       "       4.7918671e-05, 6.8865615e-05, 1.6892354e-06, 9.7056409e-06,\n",
       "       3.4734988e-04, 4.6757417e-05, 4.2662895e-04, 1.6829276e-03,\n",
       "       1.4764073e-03, 8.8718778e-04, 3.4981531e-07, 4.2916491e-04,\n",
       "       9.3979461e-06, 4.6433383e-05, 1.6690904e-06, 3.0563290e-06,\n",
       "       5.2786800e-05, 4.2065323e-05, 8.4934063e-06, 8.6355336e-05,\n",
       "       9.1626016e-06, 6.9606281e-06, 3.5719309e-05, 1.9164112e-05,\n",
       "       7.5730073e-05, 7.9671981e-06, 3.2862266e-05, 2.2319888e-04,\n",
       "       3.1251395e-06, 1.1362290e-05, 2.4580715e-06, 8.5346575e-05,\n",
       "       2.2029283e-06, 4.7831412e-07], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 벡터의 원소 합은 1입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블과 손실을 다루는 다른 방법\n",
    "\n",
    "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 10,  1,  4,  4,  3,  3,  3,  3,  3], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 충분히 큰 중간층을 두어야 하는 이유\n",
    "\n",
    "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 149us/step - loss: 2.7341 - acc: 0.3132 - val_loss: 2.0029 - val_acc: 0.5680\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 1.6979 - acc: 0.5988 - val_loss: 1.5971 - val_acc: 0.6100\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 1.3690 - acc: 0.6571 - val_loss: 1.4358 - val_acc: 0.6440\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 1.1725 - acc: 0.7021 - val_loss: 1.3667 - val_acc: 0.6740\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 1.0356 - acc: 0.7405 - val_loss: 1.3303 - val_acc: 0.6950\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.9429 - acc: 0.7553 - val_loss: 1.3134 - val_acc: 0.6980\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.8692 - acc: 0.7658 - val_loss: 1.3253 - val_acc: 0.7020\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.8131 - acc: 0.7759 - val_loss: 1.3368 - val_acc: 0.7060\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.7631 - acc: 0.7889 - val_loss: 1.3619 - val_acc: 0.7120\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.7184 - acc: 0.7962 - val_loss: 1.3647 - val_acc: 0.7070\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.6812 - acc: 0.8018 - val_loss: 1.4477 - val_acc: 0.7100\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.6467 - acc: 0.8097 - val_loss: 1.4424 - val_acc: 0.7050\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.6144 - acc: 0.8186 - val_loss: 1.4910 - val_acc: 0.7120\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.5899 - acc: 0.8280 - val_loss: 1.5345 - val_acc: 0.7110\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.5647 - acc: 0.8322 - val_loss: 1.5641 - val_acc: 0.7120\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.5379 - acc: 0.8413 - val_loss: 1.5839 - val_acc: 0.7100\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.5170 - acc: 0.8444 - val_loss: 1.5703 - val_acc: 0.7110\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.4971 - acc: 0.8515 - val_loss: 1.6325 - val_acc: 0.7090\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.4763 - acc: 0.8553 - val_loss: 1.6477 - val_acc: 0.7100\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 0.4612 - acc: 0.8583 - val_loss: 1.6912 - val_acc: 0.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f2b007748>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 실험\n",
    "\n",
    "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
    "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "다음은 이 예제에서 배운 것들입니다.\n",
    "\n",
    "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
    "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
    "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
    "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
    "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
    "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
